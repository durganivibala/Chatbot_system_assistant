# ğŸ¤– Product Chatbot

A local **Retrieval-Augmented Generation (RAG)** chatbot powered by **Ollama (Llama3)** and **Streamlit**, designed for fast, offline, and intelligent product support.

---

## ğŸš€ Features

- ğŸ’¬ **100% offline chatbot** using local Ollama models  
- ğŸ§  **RAG-based knowledge grounding** using ChromaDB  
- ğŸ” **Cross Encoder re-ranking** for highly accurate retrieval  
- ğŸ—‚ï¸ **Persistent chat memory** using Streamlit session state  
- ğŸ§© **Modular architecture** to avoid circular loops and repeated model downloads  
- âš¡ Fast, simple setup and fully local processing  

---

## ğŸ” Enhanced Retrieval System

To ensure top-quality responses, the chatbot uses a **Cross Encoder** to re-rank retrieved document chunks before sending them to the LLM.

### âœ… Benefits of the Cross Encoder

- Improved semantic matching between user query and documents  
- More accurate and relevant context retrieval  
- Reduced hallucinations  
- Ideal for documents with many similar or overlapping sentences  

---

## ğŸ›¡ï¸ Modular Architecture (Avoid Circular Loops)

The project uses **separate files** for:

- â¬‡ï¸ Model downloading (Ollama, embedding models)  
- ğŸ“š Embedding generation  
- ğŸ” Cross encoder scoring  
- ğŸ’¬ LLM response generation  
- ğŸ§  Memory management  
- ğŸ¯ Retrieval pipeline  

This structure ensures:

- ğŸš« No repeated model downloads  
- ğŸš« No circular imports  
- âš¡ Smooth startup  
- ğŸ§¼ Cleaner and maintainable codebase  

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the Repository

```bash
git clone <your-repo-url>
cd <your-repo-folder>
```

### 2ï¸âƒ£ Create and Activate Virtual Environment

```bash
python -m venv venv
```

*   On **Windows**:
    ```bash
    .\venv\Scripts\activate
    ```

*   On **macOS/Linux**:
    ```bash
    source venv/bin/activate
    ```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Pull the Ollama Model

```bash
ollama pull llama3
```

### 5ï¸âƒ£ Run the Streamlit App

```bash
streamlit run app.py
```

***

## ğŸ“ Notes

- Ensure **Ollama** is installed and running locally.  
- The chatbot uses **ChromaDB** for vector storage.  
- Chat history is stored using **Streamlit session state**.  
- A **Cross Encoder** is used for high-quality chunk re-ranking.  
- Models are downloaded in a **dedicated file**, preventing circular loops and redundant downloads.

